---
title: "Activity 5 - Mini-competition Explorations"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r Loading Packages,message=FALSE,warning=FALSE}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(tidymodels))
suppressPackageStartupMessages(library(GGally))
suppressPackageStartupMessages(library(ggfortify))
library(readr)
library(skimr)
library(broom)
library(psych)
suppressPackageStartupMessages(library(Hmisc))

```


```{r Loading Data}
# Loading data using read_csv() function

students<-read_csv("~/STA631/Activities/activity-05-mini-competition/competition-files/data/allendale-students.csv",show_col_types = FALSE)

# Checking the distribution of variables using hist.data.frame() function from Hmisc package

hist.data.frame(students)



```
* From the above histogram we can observe that distance and scholarship variables are right skewed


```{r statistics of varibales}
# Using the describe function from Psych package to check the normality of variables by using skewness and kurtosis values

psych::describe(students)

```
* Even from the above describe() function from psych package we can see the kurtosis values for scholarship is are more than absolute value of 3 and distance is almost 3 which tells that the data is heavily tailed.


```{r correlation of variales,message=FALSE,warning=FALSE}
ggpairs(students)
```



```{r}
plot1<-students%>%ggplot(aes(x=housing,y=debt,fill=housing))+
  geom_boxplot()+
  labs(title = "Rleationship between Debt and Housing",
       x="Housing",
       y="Debt")

plot1

plot2<-students%>%ggplot(aes(x=major,y=debt,fill=major))+
  geom_boxplot()+
  labs(title = "Rleationship between Debt and Major",
       x="Major",
       y="Debt")

plot2

```


* By looking at the correlations between variables, we can see that distance, scholarship and parents have a correlation with debt. I have also checked the relationships between the categorical variables like housing and major with debt, but it was not so convincing to include in the model. So, I have decided to build a model with distance, scholarship and parents.


```{r regression model}
Model1<- lm(debt~distance+scholarship+parents,data=students)
summary(Model1)
plot(Model1)
```

* After building the model and checking the residual plots, I have observed that the observation 11 is a possible outlier with high leverage that can affect the model, so I have deleted that observation and built the model again.


* I have used the augment function below from brrom package to check the std.residual values to identify any potential outliers that can effect the model (any std.residual value > 3 will be a potential outlier)


```{r}
check<-broom::augment(Model1,data=students)
```

* Looks like there is one potential outlier in this model that is affecting the model which is obseravtion "11". We can observe that in the plots of the model and also the augument data frame "check". so, let's go ahead and delete the observation and see how the model perform 


```{r}
students1<-students[-11,]
Main_model<- lm(debt~distance+scholarship+parents,data=students1)
summary(Main_model)
plot(Main_model)
```


```{r}
hist.data.frame(students1)

# Since the variables distance, scholarship and debt looks skewed , lets try to use the log transformation for these variables to see if there is any difference in the model fit.

# Tranforming the data using log transformation method and adding to a new data frame students2

students2<- students1 %>%
  mutate(log_scholarship=log(scholarship),log_distance=log(distance),log_debt=log(debt))

hist.data.frame(students2)

```


```{r}
students2[students2=="-Inf"]<-0

```

* I have made various models trying different transformed variables, we can check the model fit using the summary function on that model.

```{r}
Model2<-lm(debt~log_distance+scholarship+parents,data = students2)
Model3<-lm(debt~log_distance+log_scholarship+parents,data = students2)
Model4<-lm(log_debt~log_distance+log_scholarship+parents,data = students2)
Model5<-lm(log_debt~distance+log_scholarship+parents,data = students2)

```







## Overall, I beleive Model2 was doing better to predict or explain the variation in debt with the help of distance, scholarship and parents when deleted the observation "11" from the original dataset. The r-squared value and F-statistic value of the model is better when compared to other model. So, I have decided to go with this model as my final model.



## Assumptions of the model

* Linearity - Looks like the model has met the assumption of linearity fairly
* Constant variance - This assumption was also fairly met as the residuals almost spread equally along the line without any pattern
* Normality - Fairly met except for a couple at the tail
*Independence of residuals - We can see there are no influential observation that can affect other observations and the model. 











